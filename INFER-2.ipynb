{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utkarsh/miniconda3/envs/pytorch_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEIGHTED F1:  0.8963494218256643\n",
      "MODIFIED F1 (our metric):  0.760893406190798\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle as pkl\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from transformers import DistilBertModel , DistilBertTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "import os \n",
    "import json \n",
    "def transform_conversations(data, is_test=False):\n",
    "    transformed_data = []\n",
    "    if is_test:\n",
    "        for conversation in data:\n",
    "            transformed_conversation = {\n",
    "                \"conversation_ID\": conversation[\"conversation_ID\"],\n",
    "                \"conversation\": []\n",
    "            }\n",
    "            for utterance in conversation[\"conversation\"]:\n",
    "                transformed_text = f\"{utterance['speaker']} said: {utterance['text']}\"\n",
    "                transformed_conversation[\"conversation\"].append({\n",
    "                    \"utterance_ID\": utterance[\"utterance_ID\"],\n",
    "                    \"text\": transformed_text,\n",
    "                    \"speaker\": utterance[\"speaker\"]\n",
    "                })\n",
    "            transformed_data.append(transformed_conversation)\n",
    "        return transformed_data\n",
    "\n",
    "    else: \n",
    "        for conversation in data:\n",
    "            transformed_conversation = {\n",
    "                \"conversation_ID\": conversation[\"conversation_ID\"],\n",
    "                \"conversation\": [],\n",
    "                \"emotion-cause_pairs\": conversation[\"emotion-cause_pairs\"]\n",
    "            }\n",
    "            fluency = {'neutral':'neutrally', 'joy':'joyfully', 'sadness':'sadly', 'anger':'angrily', 'fear':'fearfully', 'surprise':'surprisingly', 'disgust':'disgustingly'}\n",
    "            for utterance in conversation[\"conversation\"]:\n",
    "                transformed_text = f\"{utterance['speaker']} {fluency[utterance['emotion']]} said: {utterance['text']}\"\n",
    "                transformed_conversation[\"conversation\"].append({\n",
    "                    \"utterance_ID\": utterance[\"utterance_ID\"],\n",
    "                    \"text\": transformed_text,\n",
    "                    \"speaker\": utterance[\"speaker\"],\n",
    "                    \"emotion\": utterance[\"emotion\"]\n",
    "                })\n",
    "            transformed_data.append(transformed_conversation)\n",
    "    return transformed_data\n",
    "\n",
    "def process_sliding_padded_conversation_with_speaker_bio(conversation, num_padding=2, is_test = False): ## is_test == without_emotions\n",
    "    processed = []\n",
    "    conversation_texts = [utterance[\"text\"] for utterance in conversation[\"conversation\"]]\n",
    "    speakers = [utterance[\"speaker\"] for utterance in conversation[\"conversation\"]]\n",
    "    num_utterances = len(conversation_texts)\n",
    "    padding_token = \"[PAD]\"\n",
    "    emotion_causes = {}\n",
    "    \n",
    "    if not is_test:\n",
    "        for pair in conversation[\"emotion-cause_pairs\"]:\n",
    "            target_id, cause_text = pair[0].split(\"_\")[0], pair[1].split(\"_\")[1]\n",
    "            if target_id in emotion_causes:\n",
    "                emotion_causes[target_id].append(cause_text)\n",
    "            else:\n",
    "                emotion_causes[target_id] = [cause_text]\n",
    "\n",
    "    \n",
    "    for i in range(num_utterances):\n",
    "        utterance_id_str = str(conversation[\"conversation\"][i][\"utterance_ID\"])\n",
    "        left_context_text = ([padding_token] * num_padding + conversation_texts[:i+1])[-(num_padding+1):]\n",
    "        left_context_speakers = (['None'] * num_padding + speakers[:i+1])[-(num_padding+1):]\n",
    "        right_context_text = []\n",
    "        right_context_speakers = []\n",
    "\n",
    "        # right_context_text = (conversation_texts[i+1:] + [padding_token] * num_padding)[:num_padding]\n",
    "        # right_context_speakers = (speakers[i+1:] + ['None'] * num_padding)[:num_padding]\n",
    "        \n",
    "        context_parts = left_context_text + right_context_text\n",
    "        context_speakers = left_context_speakers + right_context_speakers\n",
    "        full_text = \" [SEP] \".join(context_parts)\n",
    "        full_speakers = []\n",
    "        \n",
    "        for part, speaker in zip(context_parts, context_speakers):\n",
    "            full_speakers.extend([speaker] * len(part.split()) + ['None'])\n",
    "        full_speakers.pop()\n",
    "        \n",
    "        tokens = full_text.split()\n",
    "        bio_tags = [\"O\"] * len(tokens)\n",
    "        \n",
    "        if not is_test:\n",
    "            if utterance_id_str in emotion_causes:\n",
    "                for cause in emotion_causes[utterance_id_str]:\n",
    "                    start_pos = full_text.find(cause)\n",
    "                    if start_pos != -1:\n",
    "                        cause_tokens = cause.split()\n",
    "                        start_index = len(full_text[:start_pos].split())\n",
    "                        end_index = start_index + len(cause_tokens)\n",
    "                        if start_index < len(bio_tags):\n",
    "                            bio_tags[start_index] = \"B\"\n",
    "                            for j in range(start_index + 1, end_index):\n",
    "                                if j < len(bio_tags):\n",
    "                                    bio_tags[j] = \"I\"\n",
    "        \n",
    "            processed.append({\n",
    "                \"conversation_ID\": conversation[\"conversation_ID\"],\n",
    "                \"utterance_ID\": conversation[\"conversation\"][i][\"utterance_ID\"],\n",
    "                \"padded_text\": full_text,\n",
    "                \"bio_tags\": bio_tags, \n",
    "                \"utterance_emotion\": conversation[\"conversation\"][i][\"emotion\"], \n",
    "                \"utterance_speaker\": conversation[\"conversation\"][i][\"speaker\"],\n",
    "                \"speakers_in_context\": full_speakers\n",
    "            })\n",
    "        \n",
    "        else:\n",
    "            processed.append({\n",
    "                \"conversation_ID\": conversation[\"conversation_ID\"],\n",
    "                \"utterance_ID\": conversation[\"conversation\"][i][\"utterance_ID\"],\n",
    "                \"padded_text\": full_text,\n",
    "                \"utterance_speaker\": conversation[\"conversation\"][i][\"speaker\"],\n",
    "                \"speakers_in_context\": full_speakers\n",
    "            })\n",
    "        \n",
    "    return processed\n",
    "\n",
    "\n",
    "def transform_json(input_file_path=\"Subtask_1_train.json\",output_file_path = \"train_final.json\", is_test = False) :\n",
    "    import json\n",
    "    data = []\n",
    "    with open(input_file_path, \"r\") as infile:\n",
    "        data = json.load(infile)\n",
    "\n",
    "    processed_data = transform_conversations(data, is_test = is_test)\n",
    "    data=processed_data\n",
    "\n",
    "    def process_full_dataset(dataset):\n",
    "        processed_dataset = []\n",
    "        for conversation in dataset:\n",
    "            processed_conversation = process_sliding_padded_conversation_with_speaker_bio(conversation, is_test = is_test)\n",
    "            processed_dataset.extend(processed_conversation)\n",
    "        return processed_dataset\n",
    "\n",
    "    full_dataset = data\n",
    "    processed_full_dataset = process_full_dataset(full_dataset)\n",
    "\n",
    "    with open(output_file_path, \"w\") as outfile:\n",
    "        json.dump(processed_full_dataset, outfile)\n",
    "\n",
    "\n",
    "transform_json(\"train_file_normal.json\" , \"train_file.json\", is_test = False)\n",
    "# transform_json(\"Subtask_1_test.json\" , \"val_file.json\", is_test = True)\n",
    "transform_json(\"val_file_normal.json\" , \"val_file.json\", is_test = False)\n",
    "\n",
    "\n",
    "class CPI_Dataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.data = pd.read_json(filename)\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        self.sentence_encoder = SentenceTransformer('all-mpnet-base-v2')\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def get_new_labels(self, text, labels, speakers):\n",
    "        tokens = text.split()\n",
    "        new_labels = [0]\n",
    "        new_speakers = [\"None\"]\n",
    "\n",
    "        for word, label, speaker in zip(tokens, labels, speakers):\n",
    "            tokenised_word = self.tokenizer.tokenize(word)\n",
    "            n_subwords = len(tokenised_word)\n",
    "            if label == 'O':\n",
    "                new_labels.extend([0] * n_subwords)\n",
    "            elif label == 'B':\n",
    "                new_labels.append(1)\n",
    "                new_labels.extend([2] * (n_subwords - 1))\n",
    "            elif label == 'I':\n",
    "                new_labels.extend([2] * n_subwords)\n",
    "\n",
    "            new_speakers.extend([speaker] * n_subwords)\n",
    "\n",
    "        new_labels.append(0)\n",
    "        new_speakers.append(\"None\")\n",
    "        return new_labels, new_speakers\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        sample =  self.data.iloc[idx]\n",
    "        text = sample['padded_text']\n",
    "        labels = sample['bio_tags']\n",
    "        speakers = sample['speakers_in_context']\n",
    "\n",
    "        sentences = text.split('[SEP]')\n",
    "        sentence_encoding = self.sentence_encoder.encode(sentences)\n",
    "\n",
    "        new_labels, new_speakers = self.get_new_labels(text, labels, speakers)\n",
    "\n",
    "        tokenized_text = self.tokenizer(text, return_tensors='pt')\n",
    "\n",
    "        return {\n",
    "            'input_ids': tokenized_text['input_ids'].squeeze(),\n",
    "            'attention_mask': tokenized_text['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(new_labels),\n",
    "            'speakers': new_speakers,\n",
    "            'sentence_encoding': torch.tensor(sentence_encoding)\n",
    "        }\n",
    "\n",
    "\n",
    "class CPI(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CPI, self).__init__()\n",
    "        \n",
    "        self.window_size = 5\n",
    "\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=768, num_heads=1)\n",
    "\n",
    "        self.personality_dict = pkl.load(open(\"personality_dict.pkl\", \"rb\"))\n",
    "        self.personality_dict[\"None\"] = torch.zeros(1, 16)\n",
    "\n",
    "        self.bert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(1552, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 3)\n",
    "        )\n",
    "\n",
    "    def personality_embedding(self, speaker):\n",
    "        speaker_personality_list = []\n",
    "        for i in speaker:\n",
    "            spk = i[0].lower()\n",
    "            if spk == 'none':\n",
    "                speaker_personality_list.append(torch.zeros(16).to(DEVICE))\n",
    "            else:\n",
    "                speaker_personality_list.append(self.personality_dict[spk][0])\n",
    "        \n",
    "        speaker_personality = torch.stack(speaker_personality_list).to(DEVICE)\n",
    "        speaker_personality = speaker_personality.unsqueeze(0)\n",
    "        return speaker_personality\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask, speakers, sentence_encoding): \n",
    "\n",
    "        n = sentence_encoding.size(1)\n",
    "\n",
    "        ################ Sentence Tranformer #################\n",
    "\n",
    "        query = sentence_encoding[0][-1] # [1, 768]\n",
    "        query = query.repeat(sentence_encoding.size(1), 1) # [n, 768]\n",
    "        query = query.unsqueeze(0) # [1, n, 768]\n",
    "\n",
    "        key = sentence_encoding # [1, n, 768]\n",
    "        value = sentence_encoding # [1, n, 768]\n",
    "\n",
    "        attention_out, _ = self.cross_attention(query, key, value) # [1, n, 768]\n",
    "        # print(len(attention_out[0]))\n",
    "        idx = 0\n",
    "        attention_embd = [torch.zeros(768).to(DEVICE)]\n",
    "        for i in range(1, input_ids.size(1)-1):\n",
    "            if input_ids[0][i] == 102:\n",
    "                idx += 1\n",
    "            attention_embd.append(attention_out[0][idx])\n",
    "\n",
    "        attention_embd.append(torch.zeros(768).to(DEVICE))\n",
    "        \n",
    "        attention_out = torch.stack(attention_embd).to(DEVICE) # [n, 768]\n",
    "        attention_out = attention_out.unsqueeze(0) # [1, n, 768]\n",
    "\n",
    "        ################ Bert Tranformer #####################\n",
    "\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        bert_embeddings = outputs.last_hidden_state\n",
    "\n",
    "        ################ Personality Embedding ###############\n",
    "\n",
    "        speaker_personality = self.personality_embedding(speakers)\n",
    "        # print(speaker_personality.size())\n",
    "\n",
    "        ################ Concatenation #######################\n",
    "\n",
    "        # print(bert_embeddings.size(), attention_out.size())\n",
    "\n",
    "        concatenated = torch.cat((bert_embeddings, attention_out, speaker_personality), dim=2) # [1, n, 1296]\n",
    "\n",
    "        ################ Fully Connected #####################\n",
    "\n",
    "        concatenated = concatenated.squeeze(0) # [n, 1296]\n",
    "        logits = self.fully_connected(concatenated) # [n, 3]\n",
    "        return logits\n",
    "    \n",
    "\n",
    "# Validation Loop\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['labels'].to(DEVICE)\n",
    "            speakers = batch['speakers']\n",
    "            sentence_encoding = batch['sentence_encoding'].to(DEVICE)\n",
    "\n",
    "            logits = model(input_ids, attention_mask, speakers, sentence_encoding)\n",
    "            # print(logits.size(), labels.size())\n",
    "            labels = F.one_hot(labels, num_classes=3).to(DEVICE)\n",
    "            loss = criterion(logits, labels.float()[0])\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dataset = CPI_Dataset(\"train_file.json\")\n",
    "train_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "criteria = nn.CrossEntropyLoss().to(DEVICE)\n",
    "model = CPI().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "val_loader = DataLoader(CPI_Dataset(\"val_file.json\"), batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "macro_f1 = 0 \n",
    "weighted_f1  = 0 \n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "def calculate_f1_score(model, val_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            speakers = batch['speakers']\n",
    "            sentence_encoding = batch['sentence_encoding'].to(device)\n",
    "            logits = model(input_ids, attention_mask, speakers, sentence_encoding)\n",
    "            predicted = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            true_labels = labels.cpu().numpy()\n",
    "            all_preds.extend(predicted)\n",
    "            all_labels.extend(true_labels[0])\n",
    "\n",
    "            \n",
    "    labels = [0, 1, 2]\n",
    "    label_wise_f1 = f1_score(all_labels, all_preds, labels=labels, average=None)\n",
    "    \n",
    "    # Print label-wise F1 scores\n",
    "\n",
    "    \n",
    "    # Calculate and plot the confusion matrix\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=labels)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "    # print overall F1\n",
    "    # precision recall \n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    global weighted_f1\n",
    "\n",
    "    weighted_f1 = fscore \n",
    "\n",
    "    \n",
    "state_dict = torch.load('model_project210.pt')\n",
    "model.load_state_dict(state_dict)\n",
    "val_loader = DataLoader(CPI_Dataset(\"val_file.json\"), batch_size=1, shuffle=True)\n",
    "model = model.to(DEVICE)\n",
    "calculate_f1_score(model, val_loader, DEVICE)\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "def calculate_f1_scoremacro(model, val_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            speakers = batch['speakers']\n",
    "            sentence_encoding = batch['sentence_encoding'].to(device)\n",
    "            logits = model(input_ids, attention_mask, speakers, sentence_encoding)\n",
    "            predicted = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            true_labels = labels.cpu().numpy()\n",
    "            all_preds.extend(predicted)\n",
    "            all_labels.extend(true_labels[0])\n",
    "\n",
    "            \n",
    "    labels = [0, 1, 2]\n",
    "    label_wise_f1 = f1_score(all_labels, all_preds, labels=labels, average=None)\n",
    "    \n",
    "    # Print label-wise F1 scores\n",
    "\n",
    "    \n",
    "    # print overall F1\n",
    "    # precision recall \n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(all_labels, all_preds, average='macro')\n",
    "    global macro_f1\n",
    "\n",
    "    macro_f1 = fscore \n",
    "\n",
    "state_dict = torch.load('model_project210.pt')\n",
    "model.load_state_dict(state_dict)\n",
    "val_loader = DataLoader(CPI_Dataset(\"val_file.json\"), batch_size=1, shuffle=True)\n",
    "model = model.to(DEVICE)\n",
    "calculate_f1_scoremacro(model, val_loader, DEVICE)\n",
    "\n",
    "print(\"WEIGHTED F1: \" , weighted_f1)\n",
    "print(\"MODIFIED F1 (our metric): \", np.sqrt(((weighted_f1**2 + macro_f1**2) / 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEIGHTED F1:  0.8963494218256643\n",
      "MACRO F1:  0.5953782538538561\n",
      "Imbalance proof F1(our metric):  0.760893406190798\n"
     ]
    }
   ],
   "source": [
    "print(\"WEIGHTED F1: \" , weighted_f1)\n",
    "print(\"MACRO F1: \", macro_f1)\n",
    "print(\"Imbalance proof F1(our metric): \", np.sqrt(((weighted_f1**2 + macro_f1**2) / 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
